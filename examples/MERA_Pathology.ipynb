{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "import pdb\n",
    "#### import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import pandas as pd\n",
    "import os \n",
    "tf.compat.v1.enable_v2_behavior\n",
    "# Import tensornetwork\n",
    "import tensornetwork as tn\n",
    "# Set the backend to tesorflow\n",
    "# (default is numpy)\n",
    "tn.set_default_backend(\"tensorflow\")\n",
    "batch_size = 32\n",
    "learning_rate = 0.0001\n",
    "class LIDC(Sequence):\n",
    "    def __init__(self, rater=4, split='Train', data_dir = './', transform=None, num_classes=2):\n",
    "        super().__init__()\n",
    "        self. num_classes = num_classes\n",
    "        self.data_dir = data_dir\n",
    "        self.rater = rater\n",
    "        self.transform = transform\n",
    "        self.data, self.targets = torch.load(data_dir+split+'.pt')\n",
    "        self.targets = self.targets.type(torch.FloatTensor)\t\t   \n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, label = self.data[index], self.targets[index]\n",
    "        if self.rater == 4:\n",
    "            label = (label.sum() > 2).type_as(self.targets)\n",
    "        else:\n",
    "            label = label[self.rater]\n",
    "        image = image.type(torch.FloatTensor)/255.0\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        label = label.numpy().astype(np.int64)\n",
    "        label = np.eye(self.num_classes)[label].astype(np.int64)\n",
    "        return image.numpy().reshape((128, 128, 1)), label\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Batcher(Sequence):\n",
    "    \"\"\"Assemble a sequence of things into a sequence of batches.\"\"\"\n",
    "    def __init__(self, sequence, batch_size=16):\n",
    "        self._batch_size = batch_size\n",
    "        self._sequence = sequence\n",
    "        self._idxs = np.arange(len(self._sequence))\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self._sequence) / self._batch_size))\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        if i >= len(self):\n",
    "            raise IndexError(\"Index out of bounds\")\n",
    "\n",
    "        start = i*self._batch_size\n",
    "        end = min(len(self._sequence), start+self._batch_size)\n",
    "        data = [self._sequence[j] for j in self._idxs[start:end]]\n",
    "        inputs = [d[0] for d in data]\n",
    "        outputs = [d[1] for d in data]\n",
    "\n",
    "        return self._stack(inputs), self._stack(outputs)\n",
    "\n",
    "    def _stack(self, data):\n",
    "        if data is None:\n",
    "            return None\n",
    "\n",
    "        if not isinstance(data[0], (list, tuple)):\n",
    "            return np.stack(data)\n",
    "\n",
    "        seq = type(data[0])\n",
    "        K = len(data[0])\n",
    "        data = seq(\n",
    "            np.stack([d[k] for d in data])\n",
    "            for k in range(K)\n",
    "        )\n",
    "\n",
    "        return data\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self._idxs)\n",
    "        self._sequence.on_epoch_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/datacommons/carin/fk43/LIDC/'\n",
    "dataset_train = LIDC(split='Train', data_dir=data_path,\n",
    "\t\t\t\t\t\ttransform=None,rater=4)\n",
    "dataset_valid = LIDC(split='Valid', data_dir=data_path,\n",
    "\t\t\t\t\t\ttransform=None,rater=4)\n",
    "dataset_test = LIDC(split='Test', data_dir=data_path,\n",
    "\t\t\t\t\t\ttransform=None,rater=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.__getitem__(1)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Batcher(dataset_train, batch_size=batch_size)\n",
    "val_data = Batcher(dataset_valid, batch_size=batch_size)\n",
    "test_data = Batcher(dataset_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridMERAin16(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, kernel_dims, bond_dims, output_dims):\n",
    "        super(GridMERAin16, self).__init__()\n",
    "        # Create the variables for the layer.\n",
    "        # In this case, the input tensor is (, 1936), we factorize it into a tensor (, 11, 11, 16)\n",
    "        # first_dim: output shape?\n",
    "        # second_dim: connect with data tensor\n",
    "        # third_dim: inter-connect\n",
    "        in_dims = int((kernel_dims//4)**2)\n",
    "        self.entanglers = []\n",
    "        self.isometries= []\n",
    "        self.kernel_dims = kernel_dims\n",
    "        self.output_dims = output_dims\n",
    "        #entanglers\n",
    "        self.entanglers1 = tf.Variable(tf.random.normal\n",
    "                                             (shape=(in_dims, in_dims, \n",
    "                                                     in_dims, in_dims, bond_dims, bond_dims, bond_dims, bond_dims),\n",
    "                                              stddev=1/5000), \n",
    "                                              trainable=True)\n",
    "        self.entanglers2 = tf.Variable(tf.random.normal\n",
    "                                             (shape=(bond_dims, bond_dims, \n",
    "                                                     bond_dims, bond_dims, bond_dims, bond_dims, bond_dims, bond_dims),\n",
    "                                              stddev=1/5000), \n",
    "                                              trainable=True)\n",
    "        # isometries\n",
    "        self.isometries1 = [tf.Variable(tf.random.normal(shape=(in_dims, in_dims, in_dims, \n",
    "                                                                            bond_dims, bond_dims)\n",
    "                                                                     , stddev=1.0/10*5000),\n",
    "                                            trainable=True), \n",
    "                           tf.Variable(tf.random.normal(shape=(in_dims, in_dims, bond_dims, \n",
    "                                                                            in_dims, bond_dims)\n",
    "                                                                     , stddev=1.0/10*5000),\n",
    "                                            trainable=True),\n",
    "                           tf.Variable(tf.random.normal(shape=(in_dims, bond_dims, in_dims, \n",
    "                                                                            in_dims, bond_dims)\n",
    "                                                                     , stddev=1.0/10*5000),\n",
    "                                            trainable=True),\n",
    "                           tf.Variable(tf.random.normal(shape=(bond_dims, in_dims, in_dims, \n",
    "                                                                            in_dims, bond_dims)\n",
    "                                                                     , stddev=1.0/10*5000),\n",
    "                                            trainable=True)]\n",
    "        \n",
    "        self.isometries2 = tf.Variable(tf.random.normal(shape=(bond_dims, bond_dims, bond_dims, \n",
    "                                                                            bond_dims, output_dims)\n",
    "                                                                     , stddev=1.0/10*5000),\n",
    "                                            trainable=True)\n",
    "\n",
    "        #print(self.final_mps.shape)\n",
    "        self.bias = tf.Variable(tf.zeros(shape=(output_dims,)), name=\"bias\", trainable=True)\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Define the contraction.\n",
    "        # We break it out so we can parallelize a batch using tf.vectorized_map.\n",
    "        def f(input_vec, entanglers1, entanglers2, isometries1, isometries2, bias_var, kernel_dims):\n",
    "            input_vv = []\n",
    "            step = int(kernel_dims//4)\n",
    "            for i in range(4):\n",
    "                for ii in range(4):\n",
    "                    input_vv.append(tf.reshape(input_vec[i*step:i*step+step, ii*step:ii*step+step, 0], (1, step**2)))\n",
    "            input_vec = tf.concat(input_vv, axis=0)\n",
    "            input_vec = tf.reshape(input_vec, (16, step**2))\n",
    "            input_vec = tf.unstack(input_vec)\n",
    "            input_nodes = []\n",
    "            for e_iv in input_vec:\n",
    "                input_nodes.append(tn.Node(e_iv))\n",
    "            \n",
    "            e_nodes1 = tn.Node(entanglers1)\n",
    "            e_nodes2 = tn.Node(entanglers2)\n",
    "                \n",
    "                                     \n",
    "            isometries_nodes1 = []\n",
    "            for eiso in isometries1:\n",
    "                isometries_nodes1.append(tn.Node(eiso))\n",
    "            isometries_nodes2 = tn.Node(isometries2)\n",
    "            \n",
    "            \n",
    "            e_nodes1[0] ^ input_nodes[5][0]\n",
    "            e_nodes1[1] ^ input_nodes[6][0]\n",
    "            e_nodes1[2] ^ input_nodes[9][0]\n",
    "            e_nodes1[3] ^ input_nodes[10][0]\n",
    "\n",
    "            e_nodes1[4] ^ isometries_nodes1[0][3]\n",
    "            e_nodes1[5] ^ isometries_nodes1[1][2]\n",
    "            e_nodes1[6] ^ isometries_nodes1[2][1]\n",
    "            e_nodes1[7] ^ isometries_nodes1[3][0]     \n",
    "            \n",
    "            input_nodes[0][0] ^ isometries_nodes1[0][0]\n",
    "            input_nodes[1][0] ^ isometries_nodes1[0][1]\n",
    "            input_nodes[4][0] ^ isometries_nodes1[0][2]\n",
    "            \n",
    "            input_nodes[2][0] ^ isometries_nodes1[1][0]\n",
    "            input_nodes[3][0] ^ isometries_nodes1[1][1]\n",
    "            input_nodes[7][0] ^ isometries_nodes1[1][3]\n",
    "            \n",
    "            input_nodes[8][0] ^ isometries_nodes1[2][0]\n",
    "            input_nodes[12][0] ^ isometries_nodes1[2][2]\n",
    "            input_nodes[13][0] ^ isometries_nodes1[2][3]\n",
    "            \n",
    "            input_nodes[11][0] ^ isometries_nodes1[3][1]\n",
    "            input_nodes[14][0] ^ isometries_nodes1[3][2]\n",
    "            input_nodes[15][0] ^ isometries_nodes1[3][3]\n",
    "            \n",
    "            \n",
    "            isometries_nodes1[0][4] ^ e_nodes2[0]\n",
    "            isometries_nodes1[1][4] ^ e_nodes2[1]\n",
    "            isometries_nodes1[2][4] ^ e_nodes2[2]\n",
    "            isometries_nodes1[3][4] ^ e_nodes2[3]\n",
    "\n",
    "            e_nodes2[4] ^ isometries_nodes2[0]\n",
    "            e_nodes2[5] ^ isometries_nodes2[1]\n",
    "            e_nodes2[6] ^ isometries_nodes2[2]\n",
    "            e_nodes2[7] ^ isometries_nodes2[3]\n",
    "\n",
    "                            \n",
    "            nodes = tn.reachable(isometries_nodes2)\n",
    "            result = tn.contractors.greedy(nodes)\n",
    "            result = result.tensor\n",
    "            #print(result)\n",
    "            #result = (c @ b).tensor\n",
    "            # Finally, add bias.\n",
    "            return result + bias_var\n",
    "            #return result\n",
    "\n",
    "        # To deal with a batch of items, we can use the tf.vectorized_map function.\n",
    "        # https://www.tensorflow.org/api_docs/python/tf/vectorized_map\n",
    "        output = tf.vectorized_map(lambda vec: f(vec, self.entanglers1, self.entanglers2,\n",
    "                                                 self.isometries1,  self.isometries2, self.bias, self.kernel_dims), inputs)\n",
    "        return tf.reshape(output, (-1, self.output_dims))\n",
    "    \n",
    "from tensorflow.keras.layers import Lambda, Input, Concatenate, Reshape, Softmax, Dense, Flatten\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "\n",
    "def get_model(input_shape=(64, 64, 1)):\n",
    "    x_in = Input(shape=input_shape)\n",
    "    x_out_list = []\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            subx = Lambda(lambda x:x[:, 8*i:8*(i+1),8*j:8*(j+1),:] )(x_in)\n",
    "            x_out_list.append(GridMERAin16(kernel_dims=8, bond_dims=2, output_dims=1)(subx))\n",
    "    x_out = Concatenate(axis=1)(x_out_list)\n",
    "    x_out = Reshape(target_shape=(8, 8, 1))(x_out)\n",
    "    y = GridMERAin16(kernel_dims=8, bond_dims=2, output_dims=2)(x_out)\n",
    "    y = Softmax()(y)\n",
    "    return Model(inputs=x_in, outputs=y)\n",
    "\n",
    "def get_dense_model(input_shape=(64, 64, 1)):\n",
    "    x_in = Input(shape=input_shape)\n",
    "    x_out_list = []\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            subx = Lambda(lambda x:x[:, 16*i:16*(i+1),16*j:16*(j+1),:] )(x_in)\n",
    "            x_out_list.append(GridMERAin16(kernel_dims=16, bond_dims=2, output_dims=2)(subx))\n",
    "    x_out = Concatenate(axis=1)(x_out_list)\n",
    "    x_out = Flatten()(x_out)\n",
    "    y = Dense(2, activation='softmax')(x_out)\n",
    "    #x_out = Reshape(target_shape=(8, 8, 1))(x_out)\n",
    "    #y = GridMERAin16(kernel_dims=8, bond_dims=2, output_dims=2)(x_out)\n",
    "    #y = Softmax()(y)\n",
    "    return Model(inputs=x_in, outputs=y)\n",
    "\n",
    "def get_loop_model(input_shape=(64, 64, 1)):\n",
    "    x_in = Input(shape=input_shape)\n",
    "    x_out_list = []\n",
    "    MERA_layer = GridMERAin16(kernel_dims=16, bond_dims=2, output_dims=4)\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            subx = Lambda(lambda x:x[:, 16*i:16*(i+1),16*j:16*(j+1),:] )(x_in)\n",
    "            x_out_list.append(MERA_layer(subx))\n",
    "    x_out = Concatenate(axis=1)(x_out_list)\n",
    "    x_out = Flatten()(x_out)\n",
    "    y = Dense(2, activation='softmax')(x_out)\n",
    "    #x_out = Reshape(target_shape=(8, 8, 1))(x_out)\n",
    "    #y = GridMERAin16(kernel_dims=8, bond_dims=2, output_dims=2)(x_out)\n",
    "    #y = Softmax()(y)\n",
    "    return Model(inputs=x_in, outputs=y)\n",
    "\n",
    "def get_deep_model(input_shape=(64, 64, 1)):\n",
    "    x_in = Input(shape=input_shape)\n",
    "    x_in2_list = []\n",
    "    for i in range(16):\n",
    "        for j in range(16):\n",
    "            subx = Lambda(lambda x:x[:, 4*i:4*(i+1),4*j:4*(j+1),:] )(x_in)\n",
    "            x_in2_list.append(GridMERAin16(kernel_dims=1, bond_dims=2, output_dims=1)(subx))\n",
    "    x_in2 = Concatenate(axis=1)(x_in2_list)\n",
    "    x_in2 = Reshape(target_shape=(16, 16, 1))(x_in2)\n",
    "    x_out_list = []\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            subx = Lambda(lambda x:x[:, 4*i:4*(i+1),4*j:4*(j+1),:] )(x_in2)\n",
    "            x_out_list.append(GridMERAin16(kernel_dims=1, bond_dims=2, output_dims=1)(subx))\n",
    "    x_out = Concatenate(axis=1)(x_out_list)\n",
    "    x_out = Reshape(target_shape=(4, 4, 1))(x_out)\n",
    "    y = GridMERAin16(kernel_dims=1, bond_dims=2, output_dims=2)(x_out)\n",
    "    y = Softmax()(y)\n",
    "    return Model(inputs=x_in, outputs=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loop_model(input_shape=(128, 128, 1)):\n",
    "    x_in = Input(shape=input_shape)\n",
    "    x_out_list = []\n",
    "    MERA_layer = GridMERAin16(kernel_dims=4, bond_dims=2, output_dims=2)\n",
    "    for i in range(32):\n",
    "        for j in range(32):\n",
    "            subx = Lambda(lambda x:x[:, 4*i:4*(i+1),4*j:4*(j+1),:] )(x_in)\n",
    "            x_out_list.append(MERA_layer(subx))\n",
    "    x_out = Concatenate(axis=1)(x_out_list)\n",
    "    x_out = Flatten()(x_out)\n",
    "    y = Dense(2, activation='softmax')(x_out)\n",
    "    #x_out = Reshape(target_shape=(8, 8, 1))(x_out)\n",
    "    #y = GridMERAin16(kernel_dims=8, bond_dims=2, output_dims=2)(x_out)\n",
    "    #y = Softmax()(y)\n",
    "    return Model(inputs=x_in, outputs=y)\n",
    "\n",
    "def get_dense_model(input_shape=(128, 128, 1)):\n",
    "    x_in = Input(shape=input_shape)\n",
    "    x_out_list = []\n",
    "    for i in range(32):\n",
    "        for j in range(32):\n",
    "            subx = Lambda(lambda x:x[:, 4*i:4*(i+1),4*j:4*(j+1),:] )(x_in)\n",
    "            x_out_list.append(GridMERAin16(kernel_dims=4, bond_dims=2, output_dims=2)(subx))\n",
    "    x_out = Concatenate(axis=1)(x_out_list)\n",
    "    x_out = Flatten()(x_out)\n",
    "    y = Dense(2, activation='softmax')(x_out)\n",
    "    #x_out = Reshape(target_shape=(8, 8, 1))(x_out)\n",
    "    #y = GridMERAin16(kernel_dims=8, bond_dims=2, output_dims=2)(x_out)\n",
    "    #y = Softmax()(y)\n",
    "    return Model(inputs=x_in, outputs=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERA_model_64 = get_loop_model(input_shape=(128, 128, 1))\n",
    "\n",
    "MERA_model_64.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERA_model_64.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate, clipnorm=0.2), metrics=['accuracy'])\n",
    "MERA_model_64_hist = MERA_model_64.fit_generator(train_data, validation_data=val_data, epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERA_model_64.evaluate_generator(test_data, int(np.ceil(1000/batch_size)), workers = 1)\n",
    "\n",
    "tn_loss = MERA_model_64_hist.history['loss']\n",
    "tn_acc = MERA_model_64_hist.history['accuracy']\n",
    "\n",
    "\n",
    "np.savetxt('loss_MERA64.out', tn_loss, delimiter=',')  \n",
    "np.savetxt('acc_MERA64.out', tn_acc, delimiter=',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
